# 参考开源项目与论文理论基础（面向“证据-实体-事件-结论”闭环的OSINT/态势分析平台）

> 目标：为我们要做的“Palantir 级（并超越）”平台提供**可抄作业的工程范式**与**可站得住的理论底座**。
> 
> 这份清单不是“罗列”，而是按平台的关键模块，把最值得研究/复用的开源项目、标准与论文/算法，整理成可落地的参考地图。

---

## 0. 先给结论：哪些最值得优先吃透（Top Picks）

### 0.1 平台范式（直接对标我们要做的产品形态）
- **OpenCTI**：STIX2 对象模型 + 图谱 UI + Connector 生态，是“情报对象化/图谱化”的最佳开源样板之一。
- **MISP**：事件驱动的情报分享/关联/税onomies/feeds 生态极强，适合作为“外部情报源 → 证据/断言”的输入侧模板。
- **TheHive + Cortex**：面向分析师的 Case/Task/协作与 Analyzer 扩展模式，很适合借鉴“案件工作台 + 可插拔分析动作”的交互与工程结构。
- **Timesketch**：时间线分析的成熟范式（DFIR 方向），能直接给我们“时间线工作流/视图”很多启发。
- **IntelOwl / SpiderFoot / IntelMQ**：OSINT/情报采集与归一的“插件式连接器”范式（我们要学的是插件体系与编排，不是照搬 UI）。

### 0.2 关键技术地基（我们架构里最硬核的几块）
- **W3C PROV（溯源）**：把“证据链/推理链/谁在何时为何得出结论”做成标准语义，能显著提升可信与可审计。
- **STIX 2.1 / TAXII 2.1（情报对象标准）**：即使不完全采用，也强烈建议兼容导入/导出；它是外部生态互操作的“通用接口”。
- **TimeML / ISO-8601（时间表达）**：时间线平台离不开“时间归一/不确定时间/时间范围”的标准建模。
- **W3C Web Annotation Data Model（强锚点/批注）**：TextQuote/TextPosition/XPath 等选择器能把“引用定位”做成抗漂移合同（用于 Chunk anchor_set）。
- **Fellegi–Sunter（实体消歧/记录链接）**：实体合并/去重/别名归一的经典理论底座，工程上可以落到 Splink/dedupe。
- **Pirolli & Card 的 Sensemaking Loop（分析工作流理论）**：如果我们要做“工作台”，就要理解分析师真实的“找线索→建假设→验证→修正”的循环。
- **TMS/ATMS（真值维护）**：平台长期运行后不崩溃的关键，是允许“结论可撤销、可版本化、可回放”。
- **GDELT / CAMEO（国际事件编码）**：做国际事件态势分析时，这是非常实用的“事件语义编码”参考与数据源（哪怕只用其事件分类思想）。

### 0.3 本仓库（`开源项目参考/`）可直接参考的项目
- `开源项目参考/opencti`：对象化情报 + connector 生态；重点看 schema/导入导出/connector 设计（不必照搬整个平台）。
- `开源项目参考/misp`：事件/属性/对象模型 + 关联 + 分享机制；用于互操作与“外部情报源 → Evidence/SourceClaim”的输入模板。
- `开源项目参考/searxng`：元搜索入口；作为 MCP 工具 `meta_search` 的后端。
- `开源项目参考/archivebox`：归档固化（WARC/HTML/PDF/PNG/TXT/JSON）；作为 Evidence 的版本化来源（Archive-first）。
- `开源项目参考/unstructured` + `开源项目参考/tika`：文档解析与结构化抽取；作为 Chunk/SourceClaim 的上游。
- `开源项目参考/spiderfoot`：模块化 OSINT + correlations 规则范式；用于“相关性/质量闸门”的可解释规则设计。
- `开源项目参考/intelowl` / `开源项目参考/cortex`：Analyzer/Plugin 体系范式；建议以“外部服务 + MCP 调用”方式接入。
- `开源项目参考/intelmq`：Report/Event 数据格式与管线化思路；用于约束工具输出 schema 与消息契约。
- `开源项目参考/timesketch` / `开源项目参考/dfir-iris-web`：协作调查 + 时间线 + worker 模式；主要借鉴交互与分层架构。
- `开源项目参考/thehive`：历史参考（仓库已停止公开发行新版）；借鉴 Case/Task/Observable 语义即可。

---

## 1. 对标 Palantir 的开源平台（产品形态/工作流/生态）

> 这一类项目的价值不是算法，而是“**产品结构**”：对象模型、协作、插件、UI 视图、导入导出、权限与审计。

### 1.1 OpenCTI（首推）
- 我们应该学什么：
  - “对象化情报”：实体、关系、事件、指标、来源、报告之间的结构化表达
  - Connector/Importer/Enricher 的扩展体系（把采集与 enrich 变成“可插拔管线”）
  - 图谱 UI 的交互：实体侧栏、关系探索、筛选与视图保存
  - 与 STIX 的兼容策略（生态互操作）
- 我们不必照搬什么：
  - OpenCTI 的领域偏 CTI（网络威胁情报），我们做国际事件/态势会更广；但其对象化方法论非常通用。

### 1.2 MISP
- 我们应该学什么：
  - 事件（Event）作为聚合容器：attributes/objects/galaxy/tag/taxonomy
  - Feed/Sharing/Communities 的数据分发机制
  - 质量控制：标签、可信度、TLP、source 组织
- 我们的落地方式：
  - 把 MISP 当成“外部数据源/证据源”，导入后生成 Evidence + 初始 Assertions（带 provenance）

### 1.3 TheHive + Cortex
- 我们应该学什么：
  - Case/Task/Observable 的协作模型（分析师工作流）
  - Analyzer/Responder 插件化（把 enrich/动作变成可控组件）
  - 权限与审计（谁做了什么、何时做、结果是什么）

### 1.4 IntelOwl / SpiderFoot（采集/聚合型 OSINT 工具）
- 我们应该学什么：
  - 插件式“数据源连接器”
  - 扫描/采集任务的编排与结果归一
- 我们的取舍：
  - 这些项目偏“搜集与枚举”，我们更关注“证据→断言→图谱→时间线→结论”，所以借鉴其插件/编排方式即可。

### 1.5 Timesketch（时间线工作流样板）
- 我们应该学什么：
  - 时间线索引与查询体验
  - 事件归一（timestamp、source、tag、comment、aggregation）
  - 过滤器/保存搜索/协作标注

### 1.6 IntelMQ / Yeti / DFIR-IRIS（“管线化采集/调查协作”的补充样板）
- IntelMQ（CERT-Bund）：偏“消息/事件管线”，适合学习“采集→标准化→路由→入库”的工程做法（尤其是输入源繁多时）。
- Yeti（TheHive 生态）：偏 Threat Intel，但其“对象/关系 + enrich + 可追溯”的工程思路对我们通用。
- DFIR-IRIS：偏事件响应/协作（Case/Tasks/Artifacts），适合作为“调查工作台”的交互参考。

---

## 2. 证据溯源与可审计：标准/论文/工程实践

> “专业军事报告”真正的门槛不是写得像，而是**可追溯、可复核、可回放**：
> 任何一个判断都能追到证据；证据能追到原始来源；过程能审计。

### 2.1 标准：W3C PROV（PROV-DM / PROV-O）
- 解决的问题：
  - **证据链**：某个断言来自哪些来源（实体：文章、图片、视频、档案）
  - **推理链**：某个结论由哪些断言/推理步骤产生
  - **审计链**：哪个 agent/分析师在什么时候做了什么变更
- 我们的落地建议：
  - 将 Evidence/Assertion/Action/Report 都映射到 PROV 的 Entity/Activity/Agent
  - 让“回放/再现”成为一等能力（给审计与评估提供硬抓手）

### 2.2 强锚点与引用定位（W3C Web Annotation Data Model）
- 解决的问题：
  - “点开引用却定位不到原文”的慢性信任崩溃（解析器升级/网页改版/PDF 重排都会发生）
- 工程落地建议：
  - 把 Chunk 的 anchor 做成 `anchor_set`（多选择器冗余），并做健康度检测与回退：
    - HTML：XPath/CSS Selector + TextQuoteSelector + TextPositionSelector（至少两种）
    - PDF：page + bbox + TextQuote（必要时加渲染版本/页哈希）
  - “引用闭环”评测里加入 anchor_locate_rate/drift_rate（否则迟早烂）

### 2.3 可信度/不确定性表达（分析方法论基础）
- 你要查的关键词：
  - **Structured Analytic Techniques (SATs)**（Heuer 等）：把分析过程结构化，减少确认偏差
  - **ACH（Analysis of Competing Hypotheses）**：对同一事件保留多个解释，并用证据加权排除
  - **ICD 203**（美国情报界分析标准）/ “Key Judgments + Confidence” 的写作规范
- 我们的落地建议：
  - 断言对象里内置 `confidence`、`uncertainty`、`assumptions`、`alternatives`
  - 报告生成必须能“从断言/证据自动渲染 Key Judgments”，并可点击回源

### 2.4 信息可信度评估（Source Reliability / Information Credibility）
- 你要查的关键词：
  - Admiralty Code、source reliability、information credibility、mis/disinformation
- 我们的落地建议：
  - 在 Evidence 上把“来源可信度/信息可信度/独立性/时效性”结构化（而不是写在正文里）
  - 支持“同一断言多来源交叉验证”的自动评分与呈现（例如：独立来源数量、地理接近性、原始证据类型）

---

## 3. 实体消歧/实体解析（Entity Resolution / Record Linkage）

> Palantir 级平台的“核心护城河”之一就是：
> 同名不同人、别名、转写、译名、组织改名、地名变更……都要能合并/保留冲突/可回滚。

### 3.1 理论基础：Fellegi–Sunter（经典记录链接模型）
- 核心思想：
  - 把“是否同一实体”当作概率判别问题，比较字段相似度，设阈值做 match/non-match/possible-match
- 工程启发：
  - 需要可解释的“为什么合并/为什么不合并”
  - 要支持人工复核与回滚

### 3.2 开源实现：Splink / dedupe（强烈建议研究）
- Splink（SQL/可扩展）
  - 适合大规模实体解析（尤其是多字段、模糊匹配、可解释权重）
- dedupe（Python）
  - 更偏交互式/半监督

### 3.3 与我们架构的结合点
- 我们应当把“合并”当作一种**Action**：
  - `MergeDecision`：输入候选实体集合 + 证据 + 理由 + 影响范围
  - 合并不是抹掉历史：保留 alias、保留原始证据指向的“当时版本”

---

## 4. 事件抽取/关系抽取/时间归一：NLP 任务与经典数据集

> 要做“证据-实体-事件-结论”，最低要求是：
> 文档里能抽到实体、关系、事件；时间能归一；冲突能显式表达。

### 4.1 关系抽取（Relation Extraction）
- 代表性数据集/论文方向关键词：
  - **DocRED**：文档级关系抽取（跨句、多跳）
  - **TACRED**：句级关系抽取
- 我们的落地：
  - 以 LLM 为主也行，但必须输出结构化 `Assertion(type=RELATION, ...)`，并绑定 evidence spans

### 4.2 事件抽取（Event Extraction / ERE）
- 代表性数据集/方向关键词：
  - **ACE 2005** / **ERE**（经典事件与实体标注体系）
  - **MAVEN-ERE**（更现代的事件体系之一）
  - 工具/模型方向：OneIE、DyGIE++（可作为关键词去研究实现思路）
- 我们的落地：
  - 事件 = `Event` 对象（who/what/where/when/why/how）
  - 每个事件由多个 Assertions 组成（参与者、地点、时间、因果/指挥链等）

### 4.3 时间表达与归一（Temporal IE）
- 代表性工具：
  - **HeidelTime**（时间表达识别与归一）
  - **SUTime**（Stanford，偏规则）
- 代表性标准：
  - **TimeML**：事件/时间/时序关系建模
- 我们的落地：
  - 断言里必须支持 `time_start/time_end` + `time_precision` + `time_source`（证据里的哪一段）
  - 支持“模糊时间/范围时间/推断时间”的显式表达

### 4.4 指代消解/跨文档同一性（Coreference & Cross-doc linking）
- 关键词：coreference resolution / entity linking / cross-document coreference
- 我们的落地：
  - Extraction 阶段做“写入时消歧”，把代词/别名尽量落到明确实体上
  - 无法确定就保留多个候选，并在冲突工作流里解决

### 4.5 Claim extraction / Fact Verification（为 SourceClaim 提供评测底座）
- 你要查的关键词：
  - claim extraction、checkworthiness、fact verification、natural language inference (NLI)
  - 数据集方向：FEVER、SciFact、FactBank、MultiFC（作为“声明→证据→支持/反驳”评测参考）
- 我们的落地：
  - 抽取先产出 **SourceClaim**（贴近原文，保留 quote + modality + speaker/attribution）
  - 再做 Assertion fusion（融合归一），并在 UI 里永远先展示“各来源怎么说”
  - 评测不仅看“断言对不对”，还要看：claim_grounding_rate / modality 抽取准确率 / 引述链正确率

---

## 5. 知识图谱与推理：从“图”到“可用结论”的方法论

### 5.1 图谱的两种主流建模（我们需要兼容两者思维）
- RDF/语义网（OWL/SHACL）：强约束、强语义、互操作
- Property Graph（Neo4j 风格）：工程实现灵活、查询直观

### 5.2 真正有用的“图谱推理”不是玄学
- 我们要的推理类型：
  - 规则推理：例如“指挥链/隶属关系/地理包含”可用规则约束
  - 约束校验：例如时间顺序不可能（事件 A 在事件 B 之后却被声明为先发生）
  - 冲突检测：同一实体同一时间段出现互斥状态
- 推荐研究关键词：
  - Truth Maintenance System（TMS / ATMS）
  - Belief Revision（AGM）

### 5.3 经典理论：TMS / ATMS（真值维护系统）
- 为什么值得：
  - 我们的平台本质上是“不断注入新证据，不断修正旧结论”的系统
  - 如果没有“可回滚的信念维护”，图谱会越长越乱
- 我们的落地：
  - Assertion + Evidence + Action 的组合，本质就是一种工程化的 TMS

---

## 6. 检索、RAG 与 GraphRAG：把“海量证据”变成“可回答”

> 报告生成只是最后一步。前面要能在海量证据里**稳定找到**支撑/反驳材料。

### 6.1 IR 基础（必须懂）
- **BM25**：稀疏检索的核心基线
- **Dense Retrieval / DPR**：向量检索的经典路线
- **Hybrid Retrieval + RRF**：混合检索与融合排序（工程上非常实用）

### 6.2 RAG 经典论文与思路关键词
- Retrieval-Augmented Generation（RAG）
- Fusion-in-Decoder（FiD）
- Query rewriting / multi-hop retrieval / iterative retrieval

### 6.3 GraphRAG（非常适合“实体-事件-证据”）
- 思想：
  - 不仅检索 chunk，而是先把知识组织成“社区/子图/主题”，再检索子图并生成答案
- 我们的落地：
  - 图谱/时间线查询 → 召回相关实体/事件/断言 → 反查 evidence → 生成 Key Judgments

### 6.4 RAG 安全与评估（把“可控/可复现”当成硬指标）
- 你要查的关键词：
  - prompt injection、RAG poisoning、data exfiltration via tools、citation grounding evaluation
- 我们的落地建议：
  - 把“网页内容/文档内容”当作**不可信数据**：只当证据，不当指令；在模型上下文中做明确分隔（例如 `UNTRUSTED_CONTENT` 区块）
  - 任何外部文本都不允许直接改变 tool policy / system prompt（策略只能来自我们自己的 policy engine）
  - 引用评估：抽样做 span-level 对齐（结论里的每句话能找到 evidence span），并做回归测试

---

## 7. 多智能体/编排框架：LangGraph、CrewAI、AutoGen、Temporal

> 这里最容易走偏：把“智能体”当产品。
> 我们要的是“稳定可控的流水线 + 可插拔的专家委员会”。

### 7.1 LangGraph（建议作为主编排）
- 价值：
  - 有状态图（state machine）更适合“采集→抽取→解析→冲突→写回→评估”的确定性流程
  - 支持 checkpoint/replay（对审计与复现很关键）
- 用法建议：
  - 数据面（写入/变更）走 LangGraph，确保确定性与可回放

### 7.2 CrewAI / AutoGen（建议作为“分析委员会/红队”）
- 价值：
  - 用多角色对同一结论做交叉质检（bias check / alternative hypotheses）
- 风险：
  - 作为主编排会导致流程不稳定、难复现、难治理

### 7.3 Temporal / Airflow / Dagster（工程编排）
- 价值：
  - 长任务、重试、幂等、队列、可视化运行历史
- 我们的策略：
  - “智能体图”（LangGraph）负责逻辑
  - “任务调度”（Temporal）负责可靠运行与 SLA

### 7.4 MCP（Model Context Protocol）与 Skill 体系：把工具/数据源变成“可治理的插件”
- MCP 的价值（对我们来说是“工具平面标准”）：
  - 统一工具调用协议：搜索、抓取、解析、归档、数据库查询等全部封装成 MCP tools
  - 隔离与治理：allow/deny 域名、robots、速率限制、缓存、审计，避免“智能体直接上网乱爬”
  - 复用生态：未来接入第三方工具更容易（工具是“能力”，不是“写死的代码”）
- Skill 的价值（对我们来说是“能力包/模板”）：
  - 把一组 MCP tools + prompts + policies + UI components 打包成可安装/可升级/可回滚的能力
  - 用 skill 做“行业模板”：例如“海军态势”“武器装备谱系”“制裁网络追踪”等

### 7.5 Deep Agents（LangGraph 之上的 agent harness / CLI）
- 项目：`langchain-ai/deepagents`（MIT）
- 价值：
  - agent harness 开箱即用：`write_todos`（规划）、文件系统工具（read/write/edit/ls/glob/grep）、子代理 `task`、大结果落盘（token eviction）、会话摘要
  - CLI 参考实现：会话恢复、skills/AGENTS.md 记忆、HITL（对写文件/执行命令等可中断审批）
- 我们怎么用：
  - 作为 LangGraph Orchestrator/Agent CLI 的“实现范式”参考；治理边界仍以我们自己的 Policy + MCP Gateway + Audit/Action 为准（deny-by-default、Action-only writes、Evidence-first/Archive-first）
- 文档：
  - https://github.com/langchain-ai/deepagents
  - https://docs.langchain.com/oss/python/deepagents/overview
  - https://docs.langchain.com/oss/python/deepagents/harness
  - https://docs.langchain.com/oss/python/deepagents/middleware
  - https://docs.langchain.com/oss/python/deepagents/cli

---

## 8. 文档采集、解析、归档与可复现（OSINT 的地基工程）

### 8.1 搜索与抓取
- **SearxNG**：自建元搜索（多引擎聚合），很适合做“可控的搜索入口”
- 抓取解析关键词：trafilatura、newspaper3k、readability、playwright

### 8.2 归档与证据固定
- **ArchiveBox**：把网页归档为可复核证据（快照/HTML/PDF/截图）
- **WARC**：Web 归档通用格式（长期保存）

### 8.3 文档解析
- **Apache Tika**：全能型文档抽取
- **unstructured**：面向 RAG 的文档分块与结构化
- **GROBID**：学术 PDF 结构化（引用/作者/章节）

---

## 9. 数据治理、可观测性与安全（把平台做成“可运行的系统”）

### 9.1 数据质量与元数据
- **Great Expectations**：数据质量规则与回归
- **OpenMetadata / Amundsen**：元数据与数据血缘（可选）

### 9.2 可观测性
- **OpenTelemetry**：trace/log/metrics 统一
- Prometheus + Grafana + Loki/Tempo：运维标配

### 9.3 策略与权限
- **OPA（Open Policy Agent）**：策略即代码（谁能看/谁能改/哪些源能抓取）
- 审计：所有写操作都必须记录 actor + rationale + inputs + outputs
- 合规策略必须工程化：
  - retention（按 case/来源配置保留期与自动清理）
  - PII 探测/脱敏/删除请求（对象层最小化，导出默认脱敏）
  - copyright/license（Evidence/Export 保留 license_note + export_restrictions）

---

## 10. 可视化前端（图谱 + 时间线 + 证据工作台）

### 10.1 图谱可视化库
- **Cytoscape.js**：非常适合关系图谱交互（社区成熟）
- **Sigma.js / Graphology**：大图性能较好
- D3：灵活但工程成本更高

### 10.2 时间线可视化
- vis-timeline / TimelineJS / ECharts timeline（按技术栈选）

### 10.3 地理空间
- MapLibre GL：开源地图渲染

---

## 11. `开源项目参考/` 目录：逐个项目怎么“参考与复用”

> 原则：优先“黑盒服务化 + MCP 工具封装”，其次借鉴“架构/数据模型/插件范式”；避免直接拷贝 AGPL 代码进核心仓库。

### 11.1 `开源项目参考/searxng`（搜索入口）
- 学什么：多引擎聚合、去追踪、可配置的搜索后端。
- 怎么用：作为 `aegi-mcp-gateway` 的 `meta_search` 后端；把 query/result/选择理由写入 tool trace，结果必须能回放。

### 11.2 `开源项目参考/archivebox`（归档固化 / Archive-first）
- 学什么：把 URL 固化为多格式产物（WARC/HTML/PDF/PNG/TXT/JSON）并可追溯。
- 怎么用：作为 `archive_url`/`snapshot_status` 类 MCP 工具；`ArtifactVersion.storage_ref + sha256` 钉到归档产物，禁止“看网页直接写结论”。

### 11.3 `开源项目参考/unstructured` + `开源项目参考/tika`（解析与结构化抽取）
- 学什么：文档拆解、分区、元素级结构化输出与 metadata。
- 怎么用：作为 `doc_parse_unstructured` / `doc_parse_tika` MCP 工具；输入必须是已归档的 ArtifactVersion（避免解析漂移无法复现）。

### 11.4 `开源项目参考/spiderfoot`（OSINT 模块与“相关性规则”范式）
- 学什么：模块化采集 + correlations（YAML 规则）如何把“采集结果 → 可解释洞察”。
- 怎么用：把 correlations 的结构当作 AEGI 的 `Signals/CoverageGate` 参考：规则是可审计的（YAML/DSL），输出必须绑定到 Evidence。

### 11.5 `开源项目参考/intelowl` / `开源项目参考/cortex`（Analyzer/Plugin 体系范式）
- 学什么：可插拔 analyzer、异步执行、统一 REST API、结果模板化。
- 怎么用：建议作为外部服务接入（MCP 调用），输出落 Evidence zone；不要把 analyzer 输出直接写成 Assertion（先 SourceClaim）。

### 11.6 `开源项目参考/intelmq`（管线与数据合同）
- 学什么：Report/Event 分层、字段命名/类型约束、collector/parser/expert/output 的可组合管线。
- 怎么用：把“工具输出 schema”做成强合同（字段命名/类型/允许为空），并为每类工具输出写最小验证器与回归用 fixtures。

### 11.7 `开源项目参考/misp` / `开源项目参考/opencti`（互操作目标与对象化参照系）
- 学什么：对象模型（MISP Event/Object/Attribute、OpenCTI/STIX2）、导入导出、connector 生态。
- 怎么用：先做导入/导出映射（MISP/STIX bundle）；内部模型不必等同，但必须可映射且可追溯。

### 11.8 `开源项目参考/timesketch` / `开源项目参考/dfir-iris-web`（协作工作台范式）
- 学什么：Case/协作、时间线视图、后台 worker、保存查询/视图/标签/评论。
- 怎么用：对标 AEGI Workbench 的 Timeline/Views/Stories/HITL；工程上借鉴“API/业务/持久化”分层与 worker 处理模型。

### 11.9 `开源项目参考/thehive`（历史语义参考）
- 学什么：Case/Task/Observable 的语义与人与工具协作流程。
- 怎么用：只借鉴交互与语义（TheHive 3/4 已停止公开发行新版，别作为核心依赖）。

### 11.10 许可证与边界（很重要）
- AGPL 项目（如 SearxNG/MISP/IntelOwl/IntelMQ/Cortex/TheHive）：优先“独立服务 + MCP 调用 + 明确边界”，不要直接拷贝代码进核心。
- Apache/MIT 等宽松协议项目：也要保留 `license_note`/来源记录，确保可审计与可导出。

---

## 12. “超过 Palantir”需要补的理论与工程护城河（我们必须额外做好的部分）

> 现实一点：Palantir 的强并不只是图谱，而是“把图谱变成可运营的分析系统”。
> 我们想超过它，必须在以下几件事上比它更狠：

- **证据与结论强绑定（Provenance-by-default）**：任何一句结论都必须可点击回源。
- **可回放与可审计（Replayable Intelligence）**：同一输入在同一配置下能复现同一产出。
- **冲突与不确定性一等公民**：允许矛盾存在，允许多假设并存，不强行“唯一真相”。
- **实体解析与版本化**：合并/拆分/重命名都可追踪与回滚。
- **连续监控与增量更新**：不是一次性报告，而是持续演进的态势图谱。
- **评估体系（Eval-as-a-Product）**：抽取准确率、引用质量、覆盖度、偏差检测、延迟/成本都要可量化。

---

## 13. 下一步建议（不打扰你，但给我们一个“研究→落地”的顺序）

1. 先把 **OpenCTI / MISP / TheHive** 的对象模型与插件体系吃透，明确我们要兼容的导入导出格式（至少 STIX/MISP）。
2. 把 **PROV + TimeML** 的核心概念融入我们自己的 Evidence/Assertion/Action 数据模型（形成硬约束）。
3. 选定实体解析路线：先上 Splink/dedupe 的可解释合并工作流，再考虑 LLM 辅助。
4. 抽取链路：先做“高精度可回溯”的 LLM 抽取（结构化输出 + spans），再逐步引入模型/规则混合与质量评估。
5. Workbench UI：图谱 + 时间线 + 证据三视图闭环做出来，再谈“报告自动写作”。
