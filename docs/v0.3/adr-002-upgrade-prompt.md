# ADR-002 升级任务

## 目标文件
`/home/user/workspace/gitcode/aegi/docs/v0.3/adr-002-quality-first-roadmap.md`

备份已存在：`adr-002-quality-first-roadmap.md.bak`

## 改动原则
- P-next-1 到 P-next-4 **不动**
- 横切面五个 **不动**
- 参考文献 **只增不删**
- P-next-5 保留锦标赛核心机制，在其上叠加常驻 agent 层
- 远景探索（P-next-6+）重新组织，加入新的核心能力
- 完整路线图总览更新
- 中文撰写，技术术语保持英文

## 具体改动

### 1. P-next-5 升级：从"临时锦标赛"到"常驻专家网络 + 锦标赛"

在 P-next-5 现有内容的基础上，增加以下层次：

#### 1.1 常驻领域专家 agent（新增，插入在"多 Agent 独立探索"之前）

核心思路：不是事件触发时临时创建 agent，而是 5-8 个常驻 agent 7×24 运行，各自维护领域知识和态势感知。

设计要点：
- 每个 agent 用独立的 OpenClaw session，cron 定时唤醒做巡检
- 每个 agent 维护自己的 memory 文件：关键实体关系、历史事件脉络、当前态势判断
- agent 类型示例：中东地缘、大国博弈、经济制裁、军事安全、能源供应链、科技竞争
- 日常巡检：监测领域相关的 GDELT 事件流、数据源更新、新闻动态
- 不需要等异常触发，agent 自己发现值得关注的变化并提交到 AEGI 证据库
- 锦标赛触发时，常驻 agent 带着积累的领域知识参与，而不是从零开始

与 OpenClaw 的集成：
- `sessions_spawn` 创建常驻 session
- `cron` 定时唤醒（每 4-6 小时巡检一次）
- memory 文件保持认知连续性
- `sessions_send` 向 AEGI 主 session 提交发现

成本估算：
- 8 agent × 4 次/天 × ~7.5k tokens = ~240k tokens/天
- 约 $5-15/天（取决于模型选择）
- 需要 ROI 追踪机制：每个 agent 的发现被采纳率、对最终分析的贡献度

#### 1.2 记忆审计机制（新增，关键约束）

常驻 agent 的记忆会积累错误。需要：
- 定期（每周）回顾自己过去的判断，对照后续发展
- 发现错误判断时主动修正 memory，不只是时间衰减（降权）而是纠正
- 记忆审计结果提交到 AEGI，作为系统偏见追踪的输入
- 红队 agent 可以审计其他 agent 的记忆，发现系统性偏见

#### 1.3 协作约束（新增，关键约束）

agent 之间的协作必须经过 AEGI 证据链，不能直接"聊天式"说服：
- agent 发现线索 → 提交到 AEGI 证据库（SourceClaim）
- 其他 agent 通过查询证据库获取信息，不是通过 sessions_send 直接交流
- 贝叶斯裁判仍然是唯一的裁决机制
- 例外：agent 可以向 AEGI 主 session 发送"建议关注"的信号，但不能直接影响其他 agent 的判断

#### 1.4 调查深度限制（新增，关键约束）

agent 的多步调查需要 checkpoint：
- 2-3 步调查链是可靠的，直接执行
- 超过 3 步时，每 2-3 步插入自动验证点（和横切面五的轨迹审计配合）
- 验证点检查：当前调查方向是否偏离原始目标、中间结论是否有证据支撑
- 验证失败时回退到上一个 checkpoint，换方向继续

#### 1.5 更新"完整自主分析循环"图

原来的循环图前面加一层：

```
常驻 agent 持续监测（7×24，各自领域）
  ↓ 发现异常或值得关注的变化
异常检测 + 常驻 agent 的领域知识
  ↓
多 Agent 深度探索（常驻 agent 带着领域知识参与，不是从零开始）
  ↓
锦标赛辩论（不变）
  ↓
...（后续不变）
```

#### 1.6 更新验收标准

在现有验收标准基础上增加：
- [ ] 常驻 agent 可运行，cron 定时巡检，memory 跨 session 持续
- [ ] 记忆审计机制可用，错误判断可被发现和修正
- [ ] agent 协作经过证据链，不直接互相说服
- [ ] 调查深度 checkpoint 机制可用
- [ ] 常驻 agent ROI 可追踪（发现采纳率、分析贡献度）

#### 1.7 更新风险表

增加：
- 常驻 agent 记忆污染：错误判断积累导致系统性偏见 → 缓解：记忆审计 + 红队审查
- 常驻 agent 成本持续消耗：ROI 不明确 → 缓解：ROI 追踪 + 动态调整 agent 数量
- agent 协作退化为群体思维 → 缓解：协作必须经过证据链 + 贝叶斯裁判

### 2. 远景探索（P-next-6+）重新组织

当前远景探索有 5 个方向（预测市场、KG推理、Bandit、多模态、War Gaming）。
保留这些，但在前面新增一个"核心能力升级"章节，包含以下内容：

#### 2.1 全局影响传播计算（新增，高优先级）

核心：事件发生时，在知识图谱上做实时传播计算，毫秒级输出"谁会受影响"。

- 不是 LLM 推理，是图算法（BFS/加权传播/PageRank 变体）
- 输入：事件涉及的实体 + Neo4j 知识图谱
- 输出：影响传播图 + 每条路径的置信度 + 预计影响时间线
- 人类分析师可能想到前 2 层影响，系统能遍历所有 2-4 跳路径
- 与现有 `neo4j_store.py` 的 `find_multi_hop_paths()` 对接
- 与 `graph_analysis.py` 的 `find_paths()` 对接

价值：从"事件发生后分析"变成"事件发生时立即计算影响传播"。这是人类做不到的。

涉及文件：新增 `services/impact_propagation.py`，修改 `gdelt_monitor.py`（事件触发传播计算）

#### 2.2 跨域异常模式自动发现（新增，高优先级）

核心：不预定义监测变量，让系统自动扫描所有信号对之间的异常关联。

- 维护全域信号池（GDELT 事件类型、经济指标、商品价格、航运数据等）
- 用信息论方法（互信息、Transfer Entropy）自动扫描所有信号对
- 发现异常关联后，LLM 负责解释"为什么这两个信号突然关联了"
- 统计方法做发现，LLM 做解释，人类做判断——三者各司其职

与 P-next-2.3 NPMI 的关系：NPMI 是在预定义变量集上做共现检测，这个是在全域信号池上做自动扫描。NPMI 是子集。

价值：发现人类认知盲区里的关联。中东专家不会关注南美锂矿，但系统能发现它们之间的异常关联。

涉及文件：新增 `services/cross_domain_scanner.py`，修改 `services/cross_correlation.py`（接入全域信号池）

#### 2.3 反事实推理引擎（新增，中优先级）

核心：结合 DoWhy 因果推断 + 知识图谱，回答"如果 X 没有发生，世界会怎样"。

- 从因果图中找到事件的因果路径
- 用 DoWhy 的反事实推断，估算移除/改变某因素后的影响
- 沿因果图传播，估算连锁影响
- 输出定量估算 + 置信区间

应用场景：
- 评估政策选项："实施 A 制裁 vs B 制裁，哪个影响更大？"
- 归因分析："当前油价上涨，多少归因于地缘因素，多少归因于供需？"
- 预测验证："如果我们的预测前提不成立，结论会怎么变？"

依赖：P-next-2.4 的 PCMCI 因果图 + 现有 DoWhy 集成

涉及文件：新增 `services/counterfactual_engine.py`，修改 `services/timeseries_causal.py`（因果图输出供反事实使用）

#### 2.4 认知框架自动发现与进化（升级现有 PiEvo 描述）

核心：不只是在固定框架集合中选择（Bandit），而是自动发现新的有效认知框架。

- 回顾历史分析中被证实正确的假设
- 分析这些假设的共同特征（关注了什么证据、推理路径、忽略了什么）
- 从特征中提取新的认知框架
- 新框架加入常驻 agent 池，用 Bandit 评估其有效性

与现有 PiEvo 描述的区别：现有描述偏理论，这里给出具体实现路径和与常驻 agent 的集成方式。

#### 2.5 专家校准闭环（新增，高优先级）

核心：专家的一次纠正影响所有未来同类分析，不只是标注"这次对/错"。

- feedback_service 从 "agree/disagree" 升级为"结构化纠正"
- 纠正类型：遗漏因素 / 错误因果 / 过度自信 / 框架错误
- 纠正内容：自然语言描述 + 影响范围（特定实体/场景类型/全局）
- 系统自动将纠正转化为：
  - 知识图谱中的新关系或约束
  - source_credibility 的权重调整
  - 认知框架的偏好调整
  - hypothesis_engine 的 prompt 约束
- 专家的角色从"质检员"变成"系统校准者"

涉及文件：修改 `feedback_service.py`（结构化纠正 schema），新增 `services/expert_calibration.py`（纠正→规则转化）

### 3. 更新 AEGI 定位描述

在"背景"或"决策"章节中，更新 AEGI 的定位描述：

旧定位：面向情报分析专家的主动式 AI 助手（高效初筛 + 结构化分析）

新定位：一个能发现人类认知盲区、能做定量反事实推理、能自动进化认知框架、能被专家持续校准的智能分析系统。

核心价值不是"替代分析师做分析"，而是：
1. 发现分析师看不到的关联（跨域异常模式）
2. 计算分析师算不出的影响（图传播 + 反事实推理）
3. 维护分析师记不住的全局图景（实时知识图谱）
4. 从专家纠正中持续进化（认知模型校准）

分析师的角色：校准系统 + 做最终判断。系统做 80% 的工作（发现、计算、关联），分析师做 20%（判断、决策、纠正），但这 20% 是最关键的。

### 4. 更新完整路线图总览

在现有总览的 P-next-5 部分更新，加入常驻 agent 层。
远景探索部分重新排序，新增的核心能力排在前面。

演进逻辑更新：
- P-next-1~3：让系统"更准"（质量驱动）
- P-next-4：让系统"更便宜"（成本驱动）
- P-next-5：让系统"持续运行、持续进化"（自主驱动）
- P-next-6+：让系统"做人类做不到的事"（认知突破）——跨域发现、定量推理、反事实分析、自动进化

## 写作要求
- 保持现有文档的风格和格式
- 每个新增部分都要有"涉及文件"说明
- 新增的验收标准用 `- [ ]` 格式
- 风险用表格格式
- 代码示例用 Python，保持简洁
- 不要重复已有内容，用"（不变）"或引用方式
- 参考文献只增不删，新增的放在对应分类下
