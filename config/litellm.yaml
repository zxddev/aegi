# LiteLLM Proxy 配置
# 文档: https://docs.litellm.ai/docs/proxy/configs

model_list:
  # 主力模型 — GPT-5.1
  - model_name: default
    litellm_params:
      model: openai/gpt-5.1
      api_key: os.environ/OPENAI_API_KEY
      api_base: os.environ/OPENAI_API_BASE

  # 快速/便宜模型（高频调用：claim 抽取等）
  - model_name: fast
    litellm_params:
      model: openai/gpt-5-nano
      api_key: os.environ/OPENAI_API_KEY
      api_base: os.environ/OPENAI_API_BASE

  # Embedding 模型（本地 vLLM BGE-M3）
  - model_name: embedding
    litellm_params:
      model: openai/embedding-3
      api_key: dummy_key
      api_base: http://host.docker.internal:8001/v1

  # GPT-5.3-Codex（2026-02-05 发布，编码专用）
  - model_name: codex
    litellm_params:
      model: openai/gpt-5.3-codex
      api_key: os.environ/OPENAI_API_KEY
      api_base: os.environ/OPENAI_API_BASE

litellm_settings:
  drop_params: true
  set_verbose: false

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  database_url: os.environ/DATABASE_URL